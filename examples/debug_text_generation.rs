//! Debug text generation with TinyLlama

use nodespace_nlp_engine::{LocalNLPEngine, NLPEngine};
use tracing_subscriber;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    println!("ğŸš€ Testing NodeSpace NLP Engine with TinyLlama model");

    // Create engine
    let engine = LocalNLPEngine::new();

    // Initialize
    println!("ğŸ“‹ Initializing engine...");
    match engine.initialize().await {
        Ok(_) => println!("âœ… Engine initialized successfully"),
        Err(e) => {
            println!("âŒ Engine initialization failed: {:?}", e);
            return Err(format!("Engine initialization failed: {:?}", e).into());
        }
    }

    // Test text generation
    println!("ğŸ“ Testing text generation...");
    let prompt = "What is a meeting?";

    match engine.generate_text(prompt).await {
        Ok(response) => {
            println!("âœ… Text generation successful!");
            println!("ğŸ“¤ Prompt: {}", prompt);
            println!("ğŸ“¥ Response: {}", response);
        }
        Err(e) => {
            println!("âŒ Text generation failed: {:?}", e);
            return Err(format!("Text generation failed: {:?}", e).into());
        }
    }

    println!("ğŸ‰ All tests completed successfully!");
    Ok(())
}
